{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dd856f",
   "metadata": {},
   "source": [
    "$ \\newcommand{\\mbf}{\\mathbf} $\n",
    "$ \\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert} $\n",
    "$ \\newcommand{\\abs}[1]{\\left\\vert#1\\right\\vert} $\n",
    "\n",
    "# Métodos iterativos\n",
    "\n",
    "## $ \\S 1 $ Introdução\n",
    "Considere um sistema linear de $ n $ equações em $ n $ variáveis $ x_1, \\dots, x_n $:\n",
    "\\begin{equation*}\n",
    "\\begin{cases}\n",
    "& a_{11} x_1 &+& a_{12}x_2 &+& \\cdots &+& a_{1n}x_n &=& b_1 \\\\\n",
    "& a_{21} x_1 &+& a_{22}x_2 &+& \\cdots &+& a_{2n}x_n &=& b_2 \\\\\n",
    "& \\vdots &+& \\vdots &+& \\cdots &+& \\vdots &=&\\vdots \\\\\n",
    "& a_{n1} x_1 &+& a_{n2}x_2 &+& \\cdots &+& a_{nn}x_n &=& b_n\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Equivalentemente, usando notação matricial:\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "ou simplesmente $ \\mbf{A}\\mbf{x} = \\mbf{b} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc31dd4",
   "metadata": {},
   "source": [
    "Até o momento discutimos apenas métodos *diretos* de solução. A sua característica principal é que, ignorando erros de arredondamento, eles obtêm a solução *exata* do sistema com um número finito de operações. Já os métodos **iterativos** partem de uma aproximação inicial $ \\mbf{x}^{(0)} $ e repetidamente a melhoram, produzindo uma seqüência $ \\big(\\mbf{x}^{(k)}\\big) $. Eles são terminados quando a variação entre duas aproximações consecutivas for julgada pequena o suficiente.\n",
    "\n",
    "A principal desvantagem dos métodos iterativos é que nem sempre a seqüência $ \\big(\\mbf{x}^{(k)}\\big) $ converge. Outra desvantagem é que geralmente eles demandam muitos recursos computacionais, por envolverem um alto número de iterações.\n",
    "\n",
    "Em compensação, eles podem ser mais adequados quando a matriz $ \\mbf{A} $ é *esparsa* (tem muitos zeros), já que só precisamos armazenar as entradas não-nulas. Ademais, os métodos iterativos são autocorretivos: erros de arredondamento (ou mesmo aritméticos) em um ciclo iterativo serão corrigidos nos ciclos seguintes.\n",
    "\n",
    "Antes de discutir quando os métodos iterativos são bem-sucedidos, precisamos de uma noção de distância e de convergência em $ \\mathbb R^n $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82755fa",
   "metadata": {},
   "source": [
    "## $ \\S 2 $ Norma e convergência\n",
    "\n",
    "Seja $ V $ um espaço vetorial de dimensão finita sobre $ \\mathbb R $; não há perda de generalidade em supor que $ V = \\mathbb R^n $ para algum $ n \\ge 1 $, para ser mais concreto. Uma **norma** em $ V $ é uma função $ \\norm{\\cdot} \\colon V \\to \\mathbb R $ satisfazendo as seguintes três propriedades:\n",
    "* $ \\norm{\\mbf v} \\ge 0 $ para todo $ \\mbf v \\in V $, com igualdade se e somente se $ \\mbf v = \\mbf 0 $.\n",
    "* $ \\norm{\\lambda \\mbf v} = \\abs{\\lambda} \\norm{\\mbf v} $ para todos $ \\lambda \\in \\mathbb R $ e  $ \\mbf v \\in V $.\n",
    "* (**desigualdade triangular**) $ \\norm{\\mbf u + \\mbf v} \\le \\norm{\\mbf u} + \\norm{\\mbf v} $ para todos $ \\mbf u,\\ \\mbf v \\in V $.\n",
    "\n",
    "**Exemplos:** Em $ \\mathbb R^3 $, seja $ \\mbf v = (x, y, z) $ um vetor arbitrário e considere as três normas seguintes:\n",
    "* A norma **euclidiana**, definida por:\n",
    "$$\n",
    "\\norm{\\mbf v}_E  = \\sqrt{x^2 + y^2 + z^2}.\n",
    "$$\n",
    "* A norma **do máximo**, definida por:\n",
    "$$\n",
    "\\norm{\\mbf v}_M  = \\max\\{\\abs{x},\\,\\abs{y},\\,\\abs{z}\\}.\n",
    "$$\n",
    "* A norma **da soma**, definida por:\n",
    "$$\n",
    "\\norm{\\mbf v}_S = \\abs{x} + \\abs{y} + \\abs{z}.\n",
    "$$\n",
    "\n",
    "**Problema 1:** Estenda as definições destas normas a um espaço $ V = \\mathbb R^n $ qualquer $ (n \\ge 1 ) $ e verifique em cada caso as três propriedades exigidas de uma norma.\n",
    "\n",
    "Um teorema de Álgebra Linear diz que quaisquer duas normas $ \\norm{\\cdot}_1 $ e $\\norm{\\cdot}_2 $ sobre um mesmo espaço vetorial *de dimensão finita* são **equivalentes** no sentido que existem constantes positivas $ c $ e $ C $ tais que\n",
    "$$\n",
    "c \\norm{\\mbf v}_1 \\le \\norm{\\mbf v}_2 \\le C \\norm{\\mbf v}_1 \\qquad \\text{para todo }\\mbf v \\in V.\n",
    "$$\n",
    "Na prática, isto significa que para todos os efeitos podemos escolher, em cada situação, a norma que for mais conveniente.\n",
    "\n",
    "**Problema 2:** Prove que em $ \\mathbb R^n $ valem as seguintes desigualdades entres as três normas, para qualquer $ \\mbf v $:\n",
    "$$\n",
    "\\norm{\\mbf v}_M \\le \\norm{\\mbf v}_E \\le \\norm{\\mbf v}_S \\le n\\norm{\\mbf v}_M.\n",
    "$$\n",
    "Isto mostra a equivalência destas três normas.\n",
    "\n",
    "Uma vez escolhida uma norma $ \\norm{\\cdot} $ qualquer para o espaço vetorial $ V $, dispomos de uma noção de *distância / proximidade* entre dois de seus elementos, dada pela norma de sua diferença. Podemos então definir o conceito de **convergência** em $ V $: uma seqüência $ \\mbf v^{(k)} \\in V $ $ (k = 1, 2, \\dots) $ *converge* a $ \\mbf v \\in V $ se e somente se para todo $ \\varepsilon > 0 $, existe $ k_0 \\in \\mathbb N $ tal que\n",
    "$$\n",
    "k \\ge k_0 \\Longrightarrow \\norm{\\mbf v^{(k)} - \\mbf v} < \\varepsilon.\n",
    "$$\n",
    "Nesta situação escrevemos\n",
    "$$\n",
    "\\mbf v = \\lim_{k \\to \\infty} \\mbf v^{(k)}\n",
    "$$\n",
    "e chamamos $ \\mbf v $ de **limite** desta seqüência.\n",
    "\n",
    "**Problema 4:** Mostre que esta definição de convergência não depende da norma escolhida. Isto é, se duas normas $ \\norm{\\cdot}_1 $ e $ \\norm{\\cdot}_2 $ em $ V $ são equivalentes e se uma seqüência $ \\big(\\mbf v^{(k)}\\big) $ converge a $\\mbf v $ com respeito a uma das normas, então ela também converge a este limite com respeito à outra norma.\n",
    "\n",
    "**Problema 5:** Prove usando indução em $ m $ e a desigualdade triangular que se $ \\mbf v_1, \\dots, \\mbf v_m $ são elementos de $ V $ $ (m \\ge 2) $, então\n",
    "$$\n",
    "\\norm{\\sum_{j=1}^m \\mbf v_j} \\le \\sum_{j=1}^m \\norm{\\mbf v_j}.\n",
    "$$\n",
    "\n",
    "Tomando $ V = \\mathbb R^1 = \\mathbb R $ e a norma usual (valor absoluto), conclua em particular que se $ a_1,\\ a_2,\\ \\dots,\\ a_n \\in \\mathbb R $, então\n",
    "$$\n",
    "\\abs{\\sum_{i=1}^m a_i} = \\abs{a_1 + a_2 + \\dots + a_m} \\le \\abs{a_1} + \\abs{a_2} + \\dots + \\abs{a_m} = \\sum_{i=1}^m \\abs{a_i}.\n",
    "$$\n",
    "\n",
    "**Problema 6:** Mostre que, com as operações usuais de soma de matrizes e multiplicação de uma matriz por um escalar, o conjunto das matrizes quadradas $ n \\times n $ ( $ n\\ge 1 $) é um espaço vetorial de dimensão $ n \\cdot n = n^2 $. (*Dica:* Exiba um isomorfismo entre este conjunto e $ \\mathbb R^{n^2} $.)\n",
    "\n",
    "📝 A norma euclidiana\n",
    "$$\n",
    "\\norm{\\mbf x} = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}\n",
    "$$\n",
    "é a mais \"natural\" em $ \\mathbb R^n $. Sua definição é sugerida pela expressão para o comprimento do segmento que liga a origem ao ponto $ \\mbf x \\in \\mathbb R^n $, pelo teorema de Pitágoras. Entretanto, a norma do máximo é superior do ponto de vista computacional, por isto ela é utilizada na maioria das implementações de métodos numéricos.\n",
    "\n",
    "⚠️ **Convenção:** *De agora em diante, utilizaremos exclusivamente a norma do máximo em $ \\mathbb R^n $ no nosso desenvolvimento, e para simplificar a notação a denotaremos simplesmente por $ \\norm{\\cdot} $.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af12b7b",
   "metadata": {},
   "source": [
    "## $ \\S 3 $ Normas de matrizes\n",
    "\n",
    "Recorde que o conjunto das matrizes $ n \\times n $ com entradas reais ou, equivalentemente, o conjunto de todas as transformações lineares $ \\mathbb R^n \\to \\mathbb R^n $, é um espaço vetorial de dimensão $ n^2 $. Sendo assim, tudo o que foi discutido na $ \\S 2 $ se aplica a ele. Em particular, há uma infinidade de normas possíveis para este espaço, todas equivalentes uma à outra. Para os nossos propósitos, a mais conveniente é a seguinte:\n",
    "$$\n",
    "\\norm{\\mbf A} = \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\abs{a_{ij}}.\n",
    "$$\n",
    "Em palavras, para calcular a norma de uma matriz $ \\mbf A $, primeiro somamos os valores absolutos das entradas da $ i $-ésima linha, depois tomamos a maior destas somas (para $ i $ variando de $ 1 $ a  $ n $).\n",
    "\n",
    "Para analisar a convergência dos métodos iterativos, necessitamos dos dois resultados seguintes. Recorde que a norma em $ \\mathbb R^n $ é sempre a norma do máximo.\n",
    "\n",
    "**Lema 3.1:** *Para qualquer matriz $ n \\times n $ e qualquer vetor $ \\mbf x \\in \\mathbb R^n $, vale:*\n",
    "$$\n",
    "\\norm{\\mbf A \\mbf x} \\le \\norm{\\mbf A} \\norm{\\mbf x}.\n",
    "$$\n",
    "\n",
    "**Prova:** Seja $ \\mbf x = (x_1, x_2, \\dots, x_n) $. Então\n",
    "\\begin{alignat*}{9}\n",
    "\\norm{\\mbf A \\mbf x} &= \\underset{1 \\le i \\le n}{\\max}\\ \\big\\vert \\big(\\mbf A \\mbf x\\big)_i\\big\\vert \\qquad & & \\text{(pela definição da norma do máximo)} \\\\\n",
    "& = \\underset{1 \\le i \\le n}{\\max}\\ \\bigg\\vert \\sum_{j=1}^n a_{ij} x_j \\bigg \\vert \\qquad & & \\text{(pela definição do produto de $ \\mbf A $ e $ \\mbf x $)}\\\\\n",
    "& \\le \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\abs{a_{ij}} \\abs{x_j}  & & \\text{(pela desigualdade triangular em $ \\mathbb R $)}  \\\\\n",
    "& \\le \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\abs{a_{ij}} \\norm{\\mbf x} \\qquad & & \\text{(pela definição da norma do máximo)} \\\\\n",
    "&= \\norm{\\mbf x}\\, \\bigg(\\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\abs{a_{ij}}\\bigg) \\qquad & & \\text{(colocando $ \\norm{\\mbf x} $ em evidência)}\\\\\n",
    "& = \\norm{\\mbf A}\\norm{\\mbf x}  \\qquad & & \\text{(pela definição da norma de $ \\mbf A $)} \\tag*{$ \\blacksquare $}\n",
    "\\end{alignat*}\n",
    "\n",
    "**Lema 3.2:** *Para quaisquer matrizes $ n \\times n $ $ \\mbf A $ e $ \\mbf B $, vale:*\n",
    "$$\n",
    "\\norm{\\mbf A \\mbf B} \\le \\norm{\\mbf A} \\norm{\\mbf B}.\n",
    "$$\n",
    "\n",
    "**Prova:** Pela definição da norma de uma matriz, temos:\n",
    "\n",
    "\\begin{alignat*}{9}\n",
    "\\norm{\\mbf A \\mbf B} &= \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\big\\vert \\big(\\mbf A\\mbf B\\big)_{ij}\\big\\vert & & \\text{(pela definição da norma de uma matriz)} \\\\\n",
    "&= \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\bigg\\vert \\sum_{k=1}^n a_{ik}b_{kj} \\bigg\\vert \\qquad & & \\text{(pela definição do produto de $ \\mbf A $ e $ \\mbf B $)}  \\\\\n",
    "&\\le \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{j=1}^n \\sum_{k=1}^n \\abs{a_{ik}}  \\abs{b_{kj}} \\qquad & & \\text{(pela desigualdade triangular em $ \\mathbb R $)}  \\\\\n",
    "&= \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{k=1}^n \\sum_{j=1}^n  \\abs{a_{ik}}\\abs{b_{kj}} \\qquad & & \\text{(trocando a ordem dos somatórios)}  \\\\\n",
    "&= \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{k=1}^n \\abs{a_{ik}}\\sum_{j=1}^n \\abs{b_{kj}} \\qquad & & \\text{(colocando $ \\abs{a_{ik}} $ em evidência)} \\\\\n",
    "&\\le \\underset{1 \\le i \\le n}{\\max}\\ \\sum_{k=1}^n \\abs{a_{ik}} \\norm{\\mbf B} \\qquad & & \\text{(pela definição da norma de $ \\mbf B $)} \\\\\n",
    "& = \\norm{\\mbf A} \\norm{\\mbf B} \\qquad & & \\text{(pela definição da norma de $ \\mbf A $)}\\tag*{$ \\blacksquare $}\n",
    "\\end{alignat*}\n",
    "\n",
    "**Corolário 3.3:** *Para qualquer matriz quadrada $ \\mbf T $ e qualquer inteiro $ k \\ge 0 $, vale:*\n",
    "$$\n",
    "\\norm{\\mbf T^k} \\le \\norm{\\mbf T}^k.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c004c",
   "metadata": {},
   "source": [
    "## $ \\S 4 $ Descrição geral dos métodos iterativos\n",
    "\n",
    "A idéia dos métodos iterativos para resolução de sistemas lineares que consideraremos é essencialmente a mesma que a do método do ponto fixo para se encontrar zeros de funções de uma variável.\n",
    "\n",
    "Seja $ \\mbf A \\mbf x = \\mbf b $ o sistema linear que gostaríamos de resolver, onde $ A $ tem dimensões $ n \\times n $. Através de manipulações algébricas simples, podemos reescrever este sistema na forma equivalente\n",
    "$$\n",
    "\\mbf x = \\mbf T \\mbf x + \\mbf c\n",
    "$$\n",
    "para escolhas apropriadas, que variam de acordo com o método, da matriz $ n \\times n $ $\\mbf T $ e do vetor-coluna $ n \\times 1 $ $ \\mbf c $. Assim, $ \\mbf x $ será solução do sistema original se e somente se for ponto fixo da transformação $ \\mbf x \\mapsto \\mbf T \\mbf x + \\mbf c $.\n",
    "\n",
    "Para encontrar este ponto fixo, a partir de uma aproximação inicial $ \\mbf{x}^{(0)} $ escolhida construímos uma seqüência $ \\big (\\mbf{x}^{(k)} \\big) $ definida por \n",
    "$$ \\mbf{x}^{(k)} = \\mbf{T} \\mbf{x}^{(k-1)} + \\mbf c .$$\n",
    "Ou seja:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d42f0",
   "metadata": {},
   "source": [
    "* $ \\mbf{x}^{(1)} = \\mbf{T} \\mbf{x}^{(0)} + \\mbf c $;\n",
    "* $ \\mbf{x}^{(2)} = \\mbf{T} \\mbf{x}^{(1)} + \\mbf c $;\n",
    "* $ \\mbf{x}^{(3)} = \\mbf{T} \\mbf{x}^{(2)} + \\mbf c $;\n",
    "* $ \\vdots $\n",
    "* $ \\mbf{x}^{(k)} = \\mbf{T} \\mbf{x}^{(k-1)} + \\mbf c $;\n",
    "* $ \\vdots $\n",
    "\n",
    "**Lema 4.1:** *Caso a seqüência $ \\big (\\mbf{x}^{(k)} \\big) $ convirja, seu limite será solução do sistema original.*\n",
    "\n",
    "**Prova:**\n",
    "Por hipótese, existe o limite $ \\mbf{x}^{(\\infty)} $ de $ \\mbf{x}^{(k)} $ conforme $ k \\to \\infty $. Obviamente, $ \\mbf{x}^{(k-1)} $ também converge para $ \\mbf{x}^{(\\infty)} $. Fazendo $ k  \\to \\infty $ na relação\n",
    "$$ \\mbf{x}^{(k)} = \\mbf{T} \\mbf{x}^{(k-1)} + \\mbf c $$\n",
    "deduzimos que\n",
    "$$ \\mbf{x}^{(\\infty)} = \\lim_k \\mbf{x}^{(k)} = \\lim_k \\big(\\mbf{T} \\mbf{x}^{(k-1)} + \\mbf c \\big) = \\lim_k \\big( \\mbf{T} \\mbf{x}^{(k-1)} \\big) + \\mbf{c} = \\mbf{T} \\big(\\lim_k \\mbf{x}^{(k-1)}\\big) + \\mbf c = \\mbf{T} \\mbf{x}^{(\\infty)} + \\mbf c.$$\n",
    "Na penúltima igualdade usamos a continuidade de $ \\mbf T $ como função $ \\mathbb R^n \\to \\mathbb R^n $ para comutar o limite com a aplicação de $ \\mbf T $.\n",
    "Como por hipótese o sistema $ \\mbf x = \\mbf{T}\\mbf{x} + \\mbf{c} $ é equivalente ao original, concluímos que $ \\mbf{x}^{(\\infty)} $ também satisfaz\n",
    "$$\n",
    "\\mbf{A}\\mbf{x}^{(\\infty)} = \\mbf{b}.\\tag*{$ \\blacksquare $}\n",
    "$$\n",
    "\n",
    "📝 A escolha da aproximação inicial $ \\mbf x^{(0)} $ é irrelevante para a convergência da seqüência $ \\mbf x^{(k)} $ resultante, significando que  se o procedimento fornece uma seqüência convergente para uma determinada escolha inicial, qualquer outra escolha também resultaria numa seqüência convergente.\n",
    "\n",
    "📝 Contudo, em geral quanto mais próxima for a aproximação inicial $ \\mbf x^{(0)} $ da solução exata $ \\mbf x^{(\\infty)} $, mais rápida será a convergência da seqüência $ \\big (\\mbf{x}^{(k)} \\big) $ produzida pelo método a esta solução exata. Na ausência de um palpite adequado, podemos tomar $ \\mbf x^{(0)} $ como a origem de $ \\mathbb R^n $ ou escolhê-lo aleatoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67228483",
   "metadata": {},
   "source": [
    "## $ \\S 5 $ Critérios de parada\n",
    "\n",
    "Como não temos tempo infinito para calcular todos os termos da seqüência $ \\big(\\mbf x^{(k)} \\big) $, temos de nos contentar em terminar o procedimento para um $ k $ apropriado. Os critérios de parada mais comuns para os métodos iterativos são:\n",
    "* $(i) $ O número de iterações excede um número máximo pré-fixado.\n",
    "* $ (ii) $ A variação absoluta entre duas aproximações consecutivas satisfaz\n",
    "$$\n",
    "\\norm{\\mbf x^{(k)} - \\mbf x^{(k - 1)}} < \\varepsilon,\n",
    "$$\n",
    "para algum $ \\varepsilon > 0 $ pré-escolhido.\n",
    "* $ (iii) $ A variação relativa entre duas aproximações consecutivas satisfaz\n",
    "$$\n",
    "\\frac{\\norm{\\mbf x^{(k)} - \\mbf x^{(k - 1)}}}{\\norm{\\mbf x^{(k)}}} < \\varepsilon,\n",
    "$$\n",
    "para algum $ \\varepsilon > 0 $ pré-escolhido.\n",
    "\n",
    "Em geral utiliza-se a combinação $ (i) + (ii) $ ou $ (i) + (iii) $. O algoritmo retorna então o termo $ \\mbf x^{(k)} $ atual como aproximação para a solução exata assim que uma das duas condições indicadas for satisfeita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a367fa6",
   "metadata": {},
   "source": [
    "## $ \\S 6 $ Critério geral de convergência\n",
    "\n",
    "Seja\n",
    "$$\n",
    "\\Delta_k = \\mbf x^{(k)} - \\mbf x^{(k-1)} \\qquad (k = 1, 2, \\dots).\n",
    "$$\n",
    "Fazendo uso repetido da relação\n",
    "$$\n",
    "\\mbf x^{(k)} = \\mbf T \\mbf x^{(k - 1)} + \\mbf c,\n",
    "$$\n",
    "deduzimos que:\n",
    "* $ \\Delta_1 = \\mbf x^{(1)} - \\mbf x^{(0)} $.\n",
    "* $ \\Delta_2 = \\mbf x^{(2)} - \\mbf x^{(1)} = \\mbf T \\big(\\mbf x^{(1)} - \\mbf x^{(0)} \\big) = \\mbf T \\Delta_1 $.\n",
    "* $ \\Delta_3 = \\mbf x^{(3)} - \\mbf x^{(2)} = \\mbf T \\big(\\mbf x^{(2)} - \\mbf x^{(1)} \\big) = \\mbf T \\Delta_2  = \\mbf T^2 \\Delta_1 $.\n",
    "* $ \\Delta_4 = \\mbf x^{(4)} - \\mbf x^{(3)} = \\mbf T \\big(\\mbf x^{(3)} - \\mbf x^{(2)} \\big) = \\mbf T \\Delta_3  = \\mbf T^3 \\Delta_1 $.\n",
    "* $\\ \\vdots $\n",
    "\n",
    "Por indução, estabelecemos que \n",
    "\\begin{equation*}\n",
    "\\boxed{\\Delta_k = \\mbf x^{(k)} - \\mbf x^{(k-1)} = \\mbf T^{k-1}\\,\\Delta_1 \\qquad (k = 1, 2, \\dots)} \\tag{1}\n",
    "\\end{equation*}\n",
    "Então, do Lema 3.1 e do Corolário 3.3, concluímos que:\n",
    "$$\n",
    "\\boxed{\\norm{\\Delta_k} \\le \\norm{\\mbf T}^{k-1} \\norm{\\Delta_1}}\n",
    "$$\n",
    "Daí deduzimos a seguinte condição suficiente para garantir que os métodos iterativos estudados mais tarde fornecem uma seqüência que converge à solução exata do sistema original.\n",
    "\n",
    "**Teorema 6.1:** *Suponha que $ \\norm{\\mbf T} < 1 $. Então a transformação $ \\mbf x \\mapsto \\mbf T \\mbf x + \\mbf c $ tem um único ponto fixo em $ \\mathbb R^n $, e a seqüência $ \\big(\\mbf x^{(k)}\\big) $ definida indutivamente por $ \\mbf x^{(k)} = \\mbf T \\mbf x^{(k - 1)} + \\mbf c $ $ (k =1, 2, \\dots ) $ converge para ele.*\n",
    "\n",
    "📝 Recorde que ainda não explicamos como a matriz $ \\mbf T $ e o vetor $ \\mbf c $ são obtidos a partir de $ \\mbf A $ e $ \\mbf b $; os detalhes dependem do método iterativo em questão. Porém, em todos os casos $ \\mbf x $ será solução exata do sistema original $ \\mbf A \\mbf x = \\mbf b $ se e somente se for ponto fixo da transformação $ \\mbf x \\mapsto \\mbf T \\mbf x + \\mbf c $. Como a hipótese do Teorema 6.1 não envolve a aproximação inicial $ \\mbf x^{(0)} $ nem do valor de $ \\mbf b $, concluímos o seguinte:\n",
    "\n",
    "**Corolário 6.2:** *Se $ \\norm{\\mbf T} < 1 $, então o método iterativo produz uma seqüência $ \\big(\\mbf x^{(k)}\\big) $ convergente à solução exata do sistema $ \\mbf A \\mbf x = \\mbf b $ não importa quem sejam $ \\mbf x^{(0)} $ e $ \\mbf b $.*\n",
    "\n",
    "**Prova do Teorema 6.1:** Primeiro mostremos a unicidade. Suponha que $ \\mbf y $ e $ \\mbf z $ sejam  pontos fixos da transformação $ \\mbf x \\mapsto \\mbf T \\mbf x + \\mbf c $. Então\n",
    "$$\n",
    "\\norm{\\mbf y - \\mbf z} = \\norm{\\big(\\mbf T \\mbf y + \\mbf c \\big) - \\big(\\mbf T \\mbf z + \\mbf c \\big)} = \\norm{\\mbf T\\big(\\mbf y - \\mbf z\\big)} \\le \\norm{\\mbf T} \\norm{\\mbf y - \\mbf z}.\n",
    "$$\n",
    "Como $ \\norm{\\mbf T} < 1 $ por hipótese, esta desigualdade implica que $ \\norm{\\mbf y - \\mbf z} = 0 $, i.e., que $ \\mbf y = \\mbf z $.\n",
    "\n",
    "Agora sejam $ m \\ge k > 0 $ dois inteiros. Então\n",
    "\\begin{alignat*}{9}\n",
    "\\norm{\\mbf x^{(m)} - \\mbf x^{(k)}} &= \\norm{\\sum_{i=k + 1}^m \\big( \\mbf x^{(i)} - \\mbf x^{(i - 1)} \\big)} & & \\\\\n",
    "& = \\norm{\\sum_{i=k + 1}^m \\mbf T^{i-1}\\Delta_1} \\\\\n",
    "& \\le \\sum_{i=k + 1}^m \\norm{\\mbf T^{i-1}\\Delta_1} \\\\\n",
    "& \\le \\sum_{i=k + 1}^m \\norm{\\mbf T}^{i-1}\\norm{\\Delta_1} \\\\\n",
    "& = \\norm{T}^k \\big(1 + \\norm{T} + \\dots + \\norm{T}^{m - k - 1}\\big)\\norm{\\Delta_1} \\\\\n",
    "& \\le \\frac{\\norm{T}^k}{1 - \\norm{T}} \\norm{\\Delta_1}.\n",
    "\\end{alignat*}\n",
    "Como $ \\norm{\\mbf T} < 1 $ por hipótese, dado $ \\varepsilon > 0 $ qualquer, existe $ k_0 \\in \\mathbb N $ tal que\n",
    "$$\n",
    "\\frac{\\norm{T}^k}{1 - \\norm{T}} < \\varepsilon\n",
    "$$\n",
    "para todo $ k \\ge k_0 $. Isto mostra que a seqüência $ \\big(\\mbf x^{(k)}\\big) $ é de Cauchy. Como $ \\mathbb R^n $ é completo, ela converge. Finalmente, pelo Lema 4.1, seu limite é obrigatoriamente um ponto fixo da transformação \n",
    "$$ \\mbf x \\mapsto \\mbf T \\mbf x + \\mbf c. \\tag*{$ \\blacksquare $}\n",
    "$$\n",
    "\n",
    "⚠️ A hipótese do Teorema 6.1 é suficiente mas *não* é necessária para a convergência, isto é, a seqüência $ \\big( \\mbf x^{(k)} \\big) $ pode convergir a um ponto fixo mesmo que $ \\norm{\\mbf T} $ não seja menor que $ 1 $."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
