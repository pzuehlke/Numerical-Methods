{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "397d3c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d16c649",
   "metadata": {},
   "source": [
    "# O método de Newton\n",
    "\n",
    "## $ \\S 1 $ Descrição do método de Newton\n",
    "\n",
    "Suponha que desejemos encontrar um zero de uma função _diferenciável_ $ f $.\n",
    "Partindo de uma estimativa inicial $ x_0 $, a idéia por trás do __método de\n",
    "Newton__ é substituir a função pela sua reta tangente na estimativa atual\n",
    "$ x_n $ e tomar a  intersecção desta com o eixo-$x$ como o valor da próxima\n",
    "estimativa $ x_{n + 1} $. \n",
    "\n",
    "Em símbolos, a reta tangente ao gráfico de $ f $ em $ x_n $ é descrita pela equação:\n",
    "\\begin{equation*}\\label{E:line}\n",
    "y = f(x_n) + f'(x_n)\\,(x - x_{n})\\,. \\tag{1}\n",
    "\\end{equation*}\n",
    "Fazendo $ y = 0 $, encontramos que a aproximação $ x_{n + 1} $ seguinte é dada por\n",
    "$$\n",
    "\\boxed{x_{n + 1} = x_n - \\frac{f(x_n)}{f'(x_n)}}\n",
    "$$\n",
    "\n",
    "📝 A expressão do lado direito em \\eqref{E:line} é o polinômio de Taylor de grau\n",
    "$ 1 $ de $ f $ ao redor de $ x_n $, às vezes chamado nos cursos de Cálculo de\n",
    "_linearização_ ou _aproximação linear_ de $ f $ aí. Portanto sob outro ponto de\n",
    "vista (completamente equivalente), o método de Newton consiste em substituir a \n",
    "função original $ f $ pelo seu polinômio de Taylor de grau 1 na estimativa atual\n",
    "e usar o zero deste como nova aproximação para o zero de $ f $.\n",
    "\n",
    "📝 O método de Newton também é conhecido como _método de Newton-Raphson_; Joseph\n",
    "Raphson (1668–1715) foi um matemático inglês contemporâneo de Newton."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f13363d7",
   "metadata": {},
   "source": [
    "__Exemplo 1:__ Rode em seqüência o código nas três células abaixo para ver uma\n",
    "animação do método de Newton aproximando um zero da função\n",
    "$ f(x) =  x^3 - 2x - 3 \\ln x $ (em $ 0.70271253 $, aproximadamente)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b80fc58",
   "metadata": {},
   "source": [
    "![Exemplo de aplicação do método de Newton](fig_2-6_exemplo_1.png\n",
    "\"Exemplo de aplicação do método de Newton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbb82b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_solution(xs: list[float], ys: list[float], freq: int = 1) -> None:\n",
    "    \"\"\"\n",
    "    Given two arrays xs and ys of the same length, prints a table whose n-th\n",
    "    line consists of three entries: the values of n, xs[n] and ys[n].\n",
    "    Parameters:\n",
    "        * The arrays xs and ys. \n",
    "        * A parameter freq used to print only one in every freq line. The\n",
    "          first and last line are always printed. If freq == 0, then only these\n",
    "          lines are printed.\n",
    "    Output: None.\n",
    "    Prints: A header and the table described above.\n",
    "    \"\"\"\n",
    "    def print_header() -> None:\n",
    "        \"\"\"\n",
    "        Prints the table's header.\n",
    "        \"\"\"\n",
    "        print(\"\\n|       n      \", end=\"\")\n",
    "        print(\"    x_n            \", end=\"\")\n",
    "        print(\"    f(x_n)      |\")\n",
    "        print(\"|=================================================|\")\n",
    "        \n",
    "    def print_line(n: int, x: float, y: float) -> None:\n",
    "        \"\"\"\n",
    "        Pretty-prints n, x and y.\n",
    "        \"\"\"\n",
    "        print(f\"|      {n:02}\", end=\"\")\n",
    "        print(f\"    {x:15.8f}\", end=\"\")\n",
    "        print(f\"    {y:15.8f}   |\")\n",
    "    \n",
    "    \n",
    "    N = len(xs)\n",
    "    if freq == 0:       # If freq == 0, print only first and last lines.\n",
    "        freq = N - 1\n",
    "    print_header()\n",
    "    print_line(0, xs[0], ys[0])\n",
    "    for n in range(1, N, freq):\n",
    "        print_line(n, xs[n], ys[n])\n",
    "    if n != N - 1:\n",
    "        print_line(n, xs[N], ys[N])\n",
    "    print(\"|_________________________________________________|\\n\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a38baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_animation(f: Callable[[float], float],\n",
    "                     df: Callable[[float], float],\n",
    "                     a: float, b :float, x: float,\n",
    "                     N: int = 4, title: str = \"\", duration: float = 0.75\n",
    "                     ) -> tuple[list[float], list[float]]:\n",
    "    \"\"\"\n",
    "    Displays an animation of Newton's method applied to a function.\n",
    "    Parameters:\n",
    "        * A differentiable real function f.\n",
    "        * Its derivative df (as a function).\n",
    "        * The two endpoints a and b of the interval in the x-axis where the\n",
    "          animation takes place.\n",
    "        * An initial estimate x for the zero in [a, b].\n",
    "        * The maximum number N of iterations.\n",
    "        * A title to be displayed at the top of the diagram.\n",
    "        * The duration of the pause between slides of the animation, in seconds.\n",
    "          Set duration = 0 to produce a figure instead of an animation.\n",
    "    Output:\n",
    "        * Two lists xs and ys containing the estimates and the values of the\n",
    "          function f at each of them.\n",
    "    Displays:\n",
    "        * The animation in a pop-up window.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    def pause(duration):\n",
    "        \"\"\"\n",
    "        Pauses the animation for duration seconds, provided duration > 0.\n",
    "        \"\"\"\n",
    "        if duration > 0:\n",
    "            plt.pause(duration)\n",
    "\n",
    "    def tangent_line_at(x_0):\n",
    "        return lambda x: f(x_0) + df(x_0) * (x - x_0)\n",
    "    \n",
    "    def iteration(x):\n",
    "        return x - f(x) / df(x)\n",
    "\n",
    "\n",
    "    cmap = plt.get_cmap(\"tab10\")               # Used to control the colors.\n",
    "    P = 200                                    # Number of points in each plot.\n",
    "    width = 1.75                               # Line width.\n",
    "    marker_size = 5\n",
    "    domain = np.linspace(a, b, P)              # Generates P nodes from a to b.\n",
    "    xs = [x]                                   # Stores the estimates.\n",
    "    for _ in range(N):                         # Filling xs.\n",
    "        xs.append(iteration(xs[-1]))\n",
    "    ys = [f(x) for x in xs]                    # Stores f of the estimates.\n",
    "    tangent_lines = [tangent_line_at(x) for x in xs]\n",
    "\n",
    "    # Generate sample points for x-intervals between consecutive estimates:\n",
    "    xs_range = [np.linspace(xs[n], xs[n + 1], P) for n in range(N)]\n",
    "    # Lists containing the x and y coordinates for plotting vertical lines:\n",
    "    xs_vert = [np.linspace(xs[n], xs[n], P) for n in range(N)]\n",
    "    ys_vert = [np.linspace(0, ys[n], P) for n in range(N)]\n",
    "\n",
    "    # Draw the graph of f:\n",
    "    plt.axhline(y=0.0, color='black', linestyle='-', lw=width)\n",
    "    plt.xlabel(\"$ x $-axis\")\n",
    "    plt.ylabel(\"$ y $-axis\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.plot(domain, f(domain), label=\"$ y = f(x) $\", lw=width)\n",
    "    plt.legend()\n",
    "\n",
    "    # Mark the initial estimate on the x-axis:\n",
    "    pause(duration)\n",
    "    plt.plot(xs[0], 0, color=cmap(1), marker=\"x\",\n",
    "             mew=width, label=f'$ x_{0} $')\n",
    "\n",
    "    for n in range(0, N):\n",
    "        # Mark x_n on the x-axis:\n",
    "        plt.plot(xs[n], 0, color=cmap(n + 1), marker=\"x\", mew=width)\n",
    "        pause(duration)\n",
    "        # Draw the segment of the line x = x_n from y = 0 to y = y_n:\n",
    "        plt.plot(xs_vert[n], ys_vert[n], linestyle='dotted',\n",
    "                 lw=width, color='black')\n",
    "        # Plot (x_n, y_n):\n",
    "        plt.plot(xs[n], ys[n], color='black', marker=\"o\", ms=marker_size)\n",
    "        pause(duration)\n",
    "        # Plot the tangent line at (x_n, f(x_n)):\n",
    "        plt.plot(xs_range[n], tangent_lines[n](xs_range[n]),\n",
    "                 linestyle='--', color=cmap(n + 2))\n",
    "        pause(duration)\n",
    "        plt.plot(xs[n + 1], 0, color=cmap(n + 2), marker=\"x\",\n",
    "                 mew=width, label=f'$ x_{n + 1} $')\n",
    "        plt.legend()\n",
    "    \n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e760b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         1.00000000        -1.00000000   |\n",
      "|      01         0.50000000         1.20444154   |\n",
      "|      02         0.66612987         0.18213330   |\n",
      "|      03         0.70134213         0.00657080   |\n",
      "|      04         0.70271052         0.00000965   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import log\n",
    "a = 0.4\n",
    "b = 1.5\n",
    "N = 4\n",
    "f = lambda x: x**3 - 2 * x - 3 * log(x)\n",
    "df = lambda x: 3 * x**2 - 2 - 3 / x\n",
    "x_0 = 1\n",
    "pause = 0.75\n",
    "titulo = \"Exemplo: Método de Newton para $ y = x^3 - 2x - 3\\,\\ln x $.\"\\\n",
    "         \"\\n Estimativa inicial $ x_0 = 1 $ e $ N = 4 $ iterações.\"\n",
    "\n",
    "xs, ys = newton_animation(f, df, a, b, x_0, N, titulo, pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff2a6572",
   "metadata": {},
   "source": [
    "__Problema 1:__ Usando o computador como uma calculadora (e apenas quando\n",
    "necessário), aplique o método de Newton para aproximar um zero das funções\n",
    "abaixo, usando $ N = 4 $ iterações e a estimativa inicial $ x_0 $ indicada:\n",
    "\n",
    "(a) $ y = xe^x - 1\\, ,\\quad  x_0 = 0 $. \n",
    "\n",
    "(b) $ y = \\arctan x - 1\\, ,\\quad  x_0 = 1 $. \n",
    "\n",
    "(c) $ y = \\ln x - 3\\, ,\\quad  x_0 = 10 $. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "663d21b5",
   "metadata": {},
   "source": [
    "## $ \\S 3 $ Implementação do método de Newton\n",
    " \n",
    "Assim como no método do ponto fixo, não dispomos de um intervalo que encaixota\n",
    "um zero nem de uma cota superior para o erro cometido que seja independente da\n",
    "função.  Por causa disto, não há um critério de parada totalmente satisfatório.\n",
    "Na implementação abaixo, o procedimento é interrompido assim que _ambas_ as\n",
    "desigualdades abaixo forem satisfeitas pela estimativa $ x_n $ atual:\n",
    "\\begin{equation*}\\label{E:error}\n",
    "\\left\\vert x_{n} - x_{n - 1} \\right\\vert < \\varepsilon \\quad \\tag{1}\n",
    "\\end{equation*}\n",
    "e\n",
    "\\begin{equation*}\\label{E:magnitude}\n",
    "\\left\\lvert f(x_n) \\right\\rvert < \\varepsilon \\,.\\tag{2}\n",
    "\\end{equation*}\n",
    "Como sempre, aqui $ \\varepsilon > 0 $ é uma tolerância previamente escolhida.\n",
    "Infelizmente, \\eqref{E:error} não previne que ainda estejamos longe do zero,\n",
    "pois esta quantidade pode ser pequena se a aproximação for muito lenta. E\n",
    "\\eqref{E:magnitude} tem o defeito de não ser invariante, no sentido que\n",
    "apesar dos zeros das funções $ f(x) $ e $ kf(x) $ ($ k \\ne 0 $ uma constante\n",
    "real) serem exatamente os mesmos, o critério pode fornecer estimativas muito\n",
    "diferentes se $ k $ está longe de $ 1 $.\n",
    "\n",
    "Como a convergência do método de Newton não é garantida, também é recomendável\n",
    "que o procedimento seja interrompido caso um número máximo de iterações seja\n",
    "violado; esta condição também está inclusa na implementação abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f63b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def newton(f: Callable[[float], float], df: Callable[[float], float],\n",
    "           x: float, eps: float = 1.0e-3, max_iter: int = 100\n",
    "           ) -> tuple[list[float], list[float]]:\n",
    "    \"\"\"\n",
    "    Applies Newton's method to try to find a zero of a function.\n",
    "    Parameters:\n",
    "        * A differentiable function f of one real variable.\n",
    "        * Its derivative df (as another function).\n",
    "        * An initial guess x for a zero.\n",
    "        * A tolerance eps such that the procedure terminates if\n",
    "            |x_n - x_{n - 1}| < eps\n",
    "          and\n",
    "            |f(x_n)| < eps\n",
    "          where x_n is the estimate provided by the current iteration.\n",
    "        * The maximum allowed number of iterations, max_iter.\n",
    "    Output:\n",
    "        * Two lists, xs and ys, containing the estimates and the values\n",
    "          of f at each of them, respectively.\n",
    "    Prints:\n",
    "        * A warning message, in case of failure.\n",
    "        * The last estimate.\n",
    "        * The value of f at this estimate.\n",
    "        * The number of iterations that were performed.\n",
    "    \"\"\"\n",
    "    def iterate(x):\n",
    "        \"\"\" Perform one step of Newton's method to yield the next estimate. \"\"\"\n",
    "        return x - f(x) / df(x)\n",
    "\n",
    "    if eps <= 0:       # Error: invalid value for eps.\n",
    "        raise ValueError(\"The tolerance must be positive!\")\n",
    "    # Check whether max_iter is a positive integer:\n",
    "    if not (isinstance(max_iter, int) and max_iter > 0):\n",
    "        raise ValueError(\"'max_iter' must be a positive integer!\")\n",
    "    x = float(x)       # Make sure x is of type float.\n",
    "    xs = [x]           # Create a list to store the estimates.\n",
    "    ys = [f(x)]        # List to store the values of f at the estimates.\n",
    "    iterations = 0     # Counter for the number of iterations.\n",
    "    error = 2 * eps    # Any value > eps will do.\n",
    "    while error >= eps and iterations < max_iter:\n",
    "        try:           # Compute the next estimate and check for overflow.\n",
    "            new_x = iterate(x)\n",
    "        except OverflowError:\n",
    "            print(\"Overflow error! Either the estimates are diverging or\"\n",
    "                  \"the derivative at the current estimate is too small.\")\n",
    "            return None, None\n",
    "        else:\n",
    "            xs.append(new_x)          # Store the new estimate.\n",
    "            ys.append(f(new_x))       # Store f of the new estimate.\n",
    "            # Update 'error':\n",
    "            error = max(abs(xs[-1] - xs[-2]), abs(ys[-1])) \n",
    "            x = new_x                 # Update x.\n",
    "            iterations += 1           # Update iteration counter.\n",
    "    \n",
    "    print(f\"After {iterations} iterations, \", end='')\n",
    "    print(f\"the estimate for the fixed point is:\\n{xs[-1]:15.8f}\\n\"\n",
    "          f\"The value of the function at this point is: \\n{ys[-1]:15.8f}\")\n",
    "    return xs, ys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30cd8a38",
   "metadata": {},
   "source": [
    "## $ \\S 4 $ Dificuldades na covergência do método de Newton: estudo de casos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9abed30",
   "metadata": {},
   "source": [
    "![Exemplo de aplicação do método de Newton](fig_2-6_exemplo_2.png\n",
    "\"Exemplo de aplicação do método de Newton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be7a6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         0.00000000         1.00000000   |\n",
      "|      01         1.00000000         2.00000000   |\n",
      "|      02         0.77777778         0.79147826   |\n",
      "|      03         0.48017397         0.57087924   |\n",
      "|      04         1.69898988        27.61388409   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import arctan, sin, cos, exp\n",
    "a = -1.1\n",
    "b = 1.0\n",
    "N = 4\n",
    "f = lambda x: 2 * x**5 - x + 1\n",
    "df = lambda x: 10 * x**4 - 1\n",
    "x_0 = 0.0\n",
    "pause = 0\n",
    "titulo = \"Método de Newton para $ y = 2x^5 - x + 1 $. Perto do extremo\"\\\n",
    "         \"\\n local, $ \\\\vert f' \\\\vert $ é pequeno; a estimativa é jogada para longe.\"\n",
    "\n",
    "xs, ys = newton_animation(f, df, a, b, x_0, N, titulo, pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce148a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         0.00000000        -2.00000000   |\n",
      "|      01        -1.00000000        -1.00000000   |\n",
      "|      02         0.00000000        -2.00000000   |\n",
      "|      03        -1.00000000        -1.00000000   |\n",
      "|      04         0.00000000        -2.00000000   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import arctan, sin, cos, exp\n",
    "a = -1.4\n",
    "b = 1.0\n",
    "N = 4\n",
    "f = lambda x: x**3 - 2 * x - 2\n",
    "df = lambda x: 3 * x**2 - 2\n",
    "x_0 = 0.0\n",
    "pause = 0.75\n",
    "titulo = \"Método de Newton para $ y = x^3 -2x - 2 $.\"\\\n",
    "         \"\\n As estimativas oscilam ao redor do extremo local\"\n",
    "\n",
    "xs, ys = newton_animation(f, df, a, b, x_0, N, titulo, pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9cc62f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         0.10000000         0.46415888   |\n",
      "|      01        -0.20000000        -0.58480355   |\n",
      "|      02         0.40000000         0.73680630   |\n",
      "|      03        -0.80000000        -0.92831777   |\n",
      "|      04         1.60000000         1.16960710   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import cbrt\n",
    "a = -1\n",
    "b = 1.7\n",
    "N = 4\n",
    "f = lambda x: cbrt(x)\n",
    "df = lambda x: 1 / (3 * cbrt(x**2))\n",
    "x_0 = 0.1\n",
    "pause = 0.0\n",
    "titulo = \"Falha do método de Newton para $ y = \\sqrt[3]{x} $.\"\\\n",
    "         \"\\n A função não é diferenciável no zero em $ x = 0 $.\"\n",
    "\n",
    "xs, ys = newton_animation(f, df, a, b, x_0, N, titulo, pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d5817a9",
   "metadata": {},
   "source": [
    "## $ \\S 5 $ Análise do erro e da convergência no método de Newton\n",
    "\n",
    "__Teorema 5.1 (fórmula de Taylor de grau $ 1 $ com resto integral):__ _Sejam $ f $ uma função\n",
    "com segunda derivada contínua num intervalo $ I $ e $ a \\in I $. Então_\n",
    "$$\n",
    "f(x) = \\underbrace{f(a) + f'(a)(x - a)}_{\\substack{\\text{polinômio de Taylor de grau $ 1 $} \\\\ \\text{de $ f $ ao redor de $ a $}}} +\n",
    "\\underbrace{\\int_a^x f''(t)(x - t)\\,dt}_{\\substack{\\text{resto na forma\n",
    "integral} \\\\ \\text{(erro cometido na aproximação)}}} \\qquad (x \\in I)\\,.\n",
    "$$\n",
    "\n",
    "__Prova:__ Pelo teorema fundamental do Cálculo vale\n",
    "$$\n",
    "f(x) = f(a) + \\int_a^x f'(t)\\,dt\\,.\n",
    "$$\n",
    "Agora basta utilizar integração por partes para reescrever a integral. Tome\n",
    "$$\n",
    "\\begin{cases}\n",
    "    u = f'(t)\\,, & du = f''(t)\\,dt \\\\\n",
    "    dv = dt\\,, & v = -(x - t)\n",
    "\\end{cases}\n",
    "$$\n",
    "Então\n",
    "\\begin{alignat*}{9}\n",
    "f(x) &= f(a) + \\int_a^x f(t)\\,dt  \\\\\n",
    "&= f(a) + \\int_a^x u\\,dv \\\\\n",
    "&= f(a) + uv \\big\\vert_a^x - \\int_a^x v\\,du \\\\\n",
    "&= f(a) -(x - t)f'(t) \\big\\vert_a^x + \\int_a^x f''(t)(x - t)\\,dt \\\\\n",
    "&= f(a) + (x - a)f'(a) + \\int_a^x f''(t)(x - t)\\,dt\\,. \\tag*{$ \\blacksquare $}\n",
    "\\end{alignat*}\n",
    "\n",
    "\n",
    "\n",
    "__Teorema 5.2 (teorema do valor médio para integrais, versão estendida):__\n",
    "_Sejam $ f,\\, g \\colon [a, b] \\to \\mathbb{R} $ funções contínuas tais que $ g $\n",
    "não troca de sinal em $ [a, b] $. Então_ \n",
    "$$\n",
    "\\int_a^b f(x)\\,g(x)\\,dx = f(c)\\int_a^bg(x)\\,dx \\qquad \\text{para algum } c \\in (a, b)\\,.\n",
    "$$\n",
    "\n",
    "__Prova:__ \n",
    "Sejam\n",
    "$$\n",
    "    m = \\min_{[a, b]} f\\quad \\text{e} \\quad M = \\max_{[a, b]} f\\,.\n",
    "$$\n",
    "Não há perda de generalidade ao se assumir que vale $ g \\ge 0 $ em $ [a, b] $,\n",
    "já que o caso em que $ g \\le 0 $ pode ser reduzido a este trocando-se $ g $ por\n",
    "$ -g $ (o que altera os sinais de ambos os lados da igualdade afirmada).\n",
    "Então, sob esta hipótese, para qualquer $ x \\in [a, b] $ temos:\n",
    "\\begin{equation*}\n",
    "    m\\,g(x) \\le f(x) g(x) \\le M\\, g(x)\\,.\n",
    "\\end{equation*}\n",
    "Integrando, deduzimos que\n",
    "\\begin{equation*}\n",
    "m \\int_a^b g(x)\\,dx \\le \\int_a^b f(x)g(x)\\,dx \\le M \\int_a^b g(x)\\,dx \\,.\n",
    "\\end{equation*}\n",
    "\n",
    "Se $ g $ é identicamente nula, a igualdade afirmada é óbvia. Caso contrário,\n",
    "sua integral sobre a $ [a, b] $ é estritamente positiva. Assim, dividindo todos\n",
    "os termos da desigualdade acima por\n",
    "$ \\int_a^b g(x)\\,dx $ concluímos que\n",
    "\\begin{equation*}\n",
    "    m \\le \\frac{\\int_a^b g(x)f(x)\\,dx}{\\int_a^b g(x)\\,dx} \\le M .\n",
    "\\end{equation*}\n",
    "Como $ f $ é contínua por hipótese e $ m $ e $ M $ são seu mínimo e máximo\n",
    "em $ [a, b] $ respectivamente, o teorema do valor intermediário garante a\n",
    "existência de um $ c \\in [a, b] $ tal que o termo do meio acima é igual a $ f(c)\n",
    "$. Ou seja,\n",
    "\\begin{equation*}\n",
    "    \\int_a^b f(x)\\,g(x)\\,dx = f(c)\\int_a^bg(x)\\,dx\n",
    "    \\qquad \\text{para algum } c \\in (a, b)\\,. \\tag*{$ \\blacksquare $}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Voltando ao estudo do método de Newton, seja $ x_n $ a $n$-ésima estimativa\n",
    "para um zero $ \\zeta $ de $ f $. Gostaríamos de obter uma fórmula relacionando\n",
    "os erros\n",
    "\\begin{equation*}\\label{E:errors}\n",
    "E_{n + 1} = \\zeta - x_{n + 1} \\quad \\text{e} \\quad E_n = \\zeta - x_n\\,. \\tag{3}\n",
    "\\end{equation*}\n",
    "\n",
    "Pela fórmula de Taylor ao redor de\n",
    "$ x_n $,\n",
    "\\begin{equation*}\\label{E:zero}\n",
    "f(\\zeta) = 0 = f(x_n) + (\\zeta - x_n)f'(x_n) +\n",
    "\\int_{x_n}^\\zeta (\\zeta - t)f''(t)\\,dt\\,. \\tag{1}\n",
    "\\end{equation*}\n",
    "Por outro lado, a próxima estimativa $ x_{n + 1} $ no método de Newton é definida\n",
    "implicitamente pela igualdade \n",
    "\\begin{equation*}\\label{E:estimate}\n",
    "0 = f(x_n) + (x_{n + 1} - x_n) f'(x_n) \\tag{2}\n",
    "\\end{equation*}\n",
    "Subtraindo \\eqref{E:estimate} de \\eqref{E:zero} deduzimos que\n",
    "$$\n",
    "0 = (\\zeta - x_{n + 1})f'(x_n) +\n",
    "\\int_{x_n}^\\zeta (\\zeta - t)f''(t)\\,dt\\,.\n",
    "$$\n",
    "Agora, usando o teorema do valor médio para integrais (com\n",
    "$ g \\leftarrow (\\zeta - t) $ e $ f \\leftarrow f'' $), concluímos\n",
    "finalmente que\n",
    "\\begin{alignat*}{9}\n",
    "0 &= (\\zeta - x_{n + 1})f'(x_n) +\n",
    "f''(c)\\int_{x_n}^\\zeta (\\zeta - t)\\,dt \\\\\n",
    "&= \\underbrace{(\\zeta - x_{n + 1})}_{E_{n + 1}}\\,f'(x_n) +\n",
    "\\frac{f''(c)}{2}\\,\\underbrace{(\\zeta - x_n)^2}_{E_n}\n",
    "\\qquad \\text{para algum $ c \\in (a, b) $\\,.}\n",
    "\\end{alignat*}\n",
    "Daí deduzimos imediatamente a seguinte relação entre o erro atual $ E_n $ e o\n",
    "próximo $ E_{n + 1} $:\n",
    "$$\n",
    "\\boxed{E_{n + 1} = -\\frac{f''(c)}{2 f'(x_n)} E_n^2}\n",
    "$$\n",
    "Aqui $ c $ é algum ponto no menor intervalo contendo $ \\zeta $, $ x_n $ e\n",
    "$ x_{n + 1} $.  Informalmente, esta fórmula significa que o próximo erro é\n",
    "aproximadamente proporcional ao _quadrado_ do anterior.\n",
    "\n",
    "__Teorema 5.3 (convergência do método de Newton):__ _Sejam $ f $ uma função\n",
    "e $ \\zeta $ um zero de $ f $. Suponha que:_\n",
    "* $ f $ _tem segunda derivada contínua num intervalo aberto contendo $ \\zeta $;_\n",
    "* $ f'(\\zeta) \\ne 0 $.\n",
    "\n",
    "_Então para toda estimativa inicial $ x_0 $ suficientemente próxima de $ \\zeta $,\n",
    "o método de Newton gera uma seqüência $ (x_n) $ que converge a $ \\zeta $._\n",
    "\n",
    "📝 Aqui \"suficientemente próxima\" significa que existe um $ \\varepsilon > 0 $\n",
    "tal que para qualquer estimativa inicial $ x_0 $ dentro do intervalo\n",
    "$ J = [\\zeta - \\varepsilon\\,,\\, \\zeta + \\varepsilon] $, a seqüência $ (x_n) $\n",
    "correspondente tem limite $ \\zeta $.\n",
    "\n",
    "__Prova:__ Seja $ I = [\\zeta - \\delta\\,,\\, \\zeta + \\delta] $ um intervalo\n",
    "centrado em $ \\zeta $ e contido no domínio de $ f $, com $ 0 < \\delta < 1 $.  A\n",
    "primeira derivada de $ f $ é automaticamente contínua porque existe $ f'' $.  Em\n",
    "particular, reduzindo $ \\delta $ se necessário podemos supor que $ f' \\ne 0 $ em\n",
    "$ I $. Por outro lado, a continuidade de $ f'' $ é garantida por hipótese. Logo\n",
    "existem:\n",
    "* $ m > 0 $ tal que $ \\left\\lvert f' \\right \\rvert > m $ em $ I $;\n",
    "* $ M > 0 $ tal que $ \\left\\lvert f'' \\right \\rvert < M $ em $ I $.\n",
    "\n",
    "Seja\n",
    "$$\n",
    "C = \\frac{M}{m}\\,.\n",
    "$$\n",
    "Se $ x_n $ e $ x_{n + 1} $ ambos pertencem a $ I $, vale\n",
    "$$\n",
    "\\left\\lvert E_{n + 1} \\right\\rvert \\le\n",
    "\\frac{C}{2}\\left\\lvert E_{n} \\right\\rvert^2\\,.\n",
    "$$\n",
    "Tome\n",
    "$$\n",
    "\\varepsilon = \\min\\Big\\{\\tfrac{1}{C}\\,,\\,\\delta \\Big\\} \\quad \\text{e}\n",
    "\\quad J = [\\zeta - \\varepsilon\\,,\\, \\zeta + \\varepsilon]\\,.\n",
    "$$\n",
    "Então se $ x_0 \\in J $, $ \\vert E_0 \\vert \\le \\varepsilon $. Logo\n",
    "\\begin{alignat*}{9}\n",
    "\\left \\lvert E_1 \\right \\rvert &\\le \\frac{C}{2}\\, \\varepsilon^2\n",
    "&\\le \\frac{C}{2}\\frac{1}{C} \\,\\varepsilon\n",
    "&= \\frac{\\varepsilon}{2}\\,.\n",
    "\\end{alignat*}\n",
    "Mais geralmente, usando o mesmo argumento prova-se por indução que\n",
    "$$\n",
    "\\left \\lvert E_n \\right \\rvert \\le \\frac{\\varepsilon}{2^n}\\,.\n",
    "$$\n",
    "Em particular, $ E_n \\to 0 $ conforme $ n \\to \\infty $. Logo $ (x_n) $\n",
    "converge a $ \\zeta $ como afirmado, desde que $ x_0 \\in J $.\n",
    "\n",
    "<div style=\"text-align: right\">$ \\blacksquare $ </div>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21f89cdd",
   "metadata": {},
   "source": [
    "## $ \\S 7 $ Método de Newton como caso especial do método do ponto fixo\n",
    "\n",
    "Nesta seção mostraremos que uma outra interpretação para o método de Newton é\n",
    "que ele é um caso especial do método do ponto fixo. Em particular, este ponto de\n",
    "vista resultará sem nenhum esforço num novo critério suficiente para\n",
    "convergência.\n",
    "\n",
    "Suponha que $ f $ tenha derivada contínua e que $ f(\\zeta) = 0 $. Seja\n",
    "$ \\alpha $ qualquer outra função diferenciável, mas que _não_ se anula \n",
    "num intervalo aberto $ J $ contendo $ \\zeta $. Então, tomando\n",
    "$$\n",
    "    \\varphi(x) = x + \\alpha(x)f(x)\\,,\n",
    "$$\n",
    "vale \n",
    "$$\n",
    "\\phantom{\\qquad ( x \\in I)}\n",
    "f(x) = 0 \\Longleftrightarrow \\varphi(x) = x \\qquad (x \\in J)\\,.\n",
    "$$\n",
    "Em palavras, em $ I $, os zeros de $ f $ são exatamente os pontos fixos de\n",
    "$ \\varphi $.\n",
    "\n",
    "O fato que podemos transformar o problema de se encontrar zeros de $ f $ no\n",
    "de se encontrar pontos fixos de outra função $ \\varphi $ não é novo, já foi\n",
    "discutido no caderno anterior. Lá foi visto que é possível garantir que o método\n",
    "do ponto fixo aplicado a $ \\varphi $ gera uma seqüência $ (x_n) $ que converge a\n",
    "$ \\zeta $ desde que tomemos a estimativa inicial $ x_0 $ para $ \\zeta $ dentro\n",
    "dum intervalo $ J \\subset I $ centrado em $ \\zeta $ onde valha\n",
    "$$\n",
    "    \\vert \\varphi'(x) \\vert \\le C \\quad\n",
    "    \\text{para alguma constante $ C < 1 $ e todo $ x \\in J $}\\,.\n",
    "$$\n",
    "Como até agora não especificamos quem deve ser $ \\alpha $, podemos escolhê-la da\n",
    "maneira mais conveniente possível, a saber, de modo que a derivada de\n",
    "$ \\varphi $ em $ \\zeta $ seja nula:\n",
    "$$\n",
    "\\varphi'(\\zeta) = 1 + \\alpha(\\zeta) f'(\\zeta) +\n",
    "\\alpha'(\\zeta) \\underbrace{f(\\zeta)}_{0} = 0\\,.\n",
    "$$\n",
    "Gostaríamos portanto que\n",
    "$$\n",
    "    \\alpha(\\zeta) = -\\frac{1}{f'(\\zeta)}\\,.\n",
    "$$\n",
    "A alternativa mais natural é definir\n",
    "$$\n",
    "    \\alpha(x) = -\\frac{1}{f'(x)}\\,.\n",
    "$$\n",
    "Fazendo esta escolha obtemos a função de iteração\n",
    "$$\n",
    "    \\boxed{\\varphi(x) = x -\\frac{f(x)}{f'(x)}}\n",
    "$$\n",
    "Vemos portanto que _para uma mesma estimativa inicial para $ x_0 $, a seqüência\n",
    "$ (x_n) $ construída através do método de Newton aplicado a $ f $ é exatamente a\n",
    "mesma que aquela construída pelo método do ponto fixo aplicado a esta função $\n",
    "\\varphi $._\n",
    "\n",
    "Em particular, aplicando o Corolário 6.5 do caderno anterior a $ \\varphi $ deduzimos\n",
    "o seguinte critério suficiente para convergência do método de Newton.\n",
    "\n",
    "__Teorema 7.1 (critério suficiente para convergência do método de Newton):__\n",
    "_Seja $ f $ uma função continuamente diferenciável que tem um zero em $ \\zeta $.\n",
    "Suponha que $ I $ seja um intervalo centrado em $ \\zeta $ onde vale_\n",
    "\\begin{equation*}\n",
    "\\left \\lvert \\frac{f(x)f''(x)}{\\big[f'(x)\\big]^2} \\right \\rvert\n",
    "\\le C < 1 \\quad \\text{para uma constante $ C $ e todo $ x \\in I $\\,.} \\tag*{4}\n",
    "\\end{equation*}\n",
    "_Então $ \\zeta $ é o único zero de $ f $ em $ I $ e a seqüência $ (x_n) $ gerada\n",
    "pelo método de Newton converge a $ \\zeta $ para qualquer estimativa inicial\n",
    "$ x_0 $ dentro de $ I $._\n",
    "\n",
    "__Prova:__ Pela regra do quociente,\n",
    "$$\n",
    "\\varphi'(x) = 1 - \\frac{f'(x)^2 - f(x)f''(x)}{\\big[f'(x)\\big]^2} = \n",
    "\\frac{f(x)f''(x)}{\\big[f'(x)\\big]^2}\\,.\n",
    "$$\n",
    "O Corolário 6.5 se aplica desde que existam uma constante positiva $ C < 1 $ e\n",
    "um intervalo $ I $ centrado em $ \\zeta $ tais que \n",
    "$$\n",
    "\\varphi'(x) \\le C \\quad \\text{para todo $ x \\in I $\\,,}\n",
    "$$\n",
    "ou seja,\n",
    "\\begin{equation*}\n",
    "\\left \\lvert \\frac{f(x)f''(x)}{\\big[f'(x)\\big]^2} \\right \\rvert\n",
    "\\le C \\,.\\tag*{$ \\blacksquare $}\n",
    "\\end{equation*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c15011f",
   "metadata": {},
   "source": [
    "\n",
    "## $ \\S 6 $ Vantagens e desvantagens do método de Newton\n",
    "\n",
    "Como visto acima, no método de Newton o erro cometido na iteração seguinte é\n",
    "aproximadamente proporcional ao *quadrado* do erro da iteração atual. Portanto\n",
    "podemos esperar que uma vez que o erro seja menor que $ 0.1 $, a cada passo o\n",
    "número de dígitos decimais de precisão aproximadamente dobrará. Dito de outra\n",
    "forma, o número de dígitos de precisão crescerá _exponencialmente_ com o número\n",
    "$ n $ de iterações.\n",
    "\n",
    "Este desempenho deve ser comparado com o do método da bisseção, em que o erro\n",
    "seguinte é aproximadamente proporcional ao erro atual (por um fator de $ 1/2 $).\n",
    "Informalmente, isto significa que uma vez que consigamos uma estimativa próxima\n",
    "o suficiente de um zero, o método de Newton convergirá _muito_ mais rapidamente\n",
    "que os outros métodos que estudamos.\n",
    "\n",
    "Outra vantagem é que para aplicar o método de Newton, não precisamos encaixotar\n",
    "o zero.\n",
    "\n",
    "Entretanto, o método de Newton tem duas desvantagens significativas:\n",
    "* Ele exige o cálculo da derivada da função à qual será aplicado.\n",
    "* Ele nem sempre funciona, ou seja, a seqüência $ (x_n) $ pode não convergir.\n",
    "\n",
    "Por causa do segundo defeito, uma estratégia mais adequada é utilizar o método\n",
    "de Newton em combinação com um mais confiável, como o método da bissecção.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b48496",
   "metadata": {},
   "source": [
    "![Exemplo de comportamento inadequado do método de Newton perto de extremos\n",
    "locais](fig_2-6_exemplo_2.png \"Exemplo de comportamento inadequado do método de\n",
    "Newton perto de extremos locais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c5f5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         0.00000000        -1.00000000   |\n",
      "|      01         1.00000000         1.71828183   |\n",
      "|      02         0.68393972         0.35534255   |\n",
      "|      03         0.57745448         0.02873389   |\n",
      "|      04         0.56722974         0.00023889   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: x * np.exp(x) - 1\n",
    "x = 0\n",
    "a = 0\n",
    "b = 1\n",
    "N = 4\n",
    "df = lambda x: np.exp(x) * (x + 1)\n",
    "eps = 1e-3\n",
    "max_iter = 100\n",
    "pause = 0.0\n",
    "xs, ys = newton_animation(f, df, a, b, x, N, \"\", pause)\n",
    "print_solution(xs, ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba3ca58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00         1.00000000        -0.21460184   |\n",
      "|      01         1.42920367        -0.03972178   |\n",
      "|      02         1.55006208        -0.00215157   |\n",
      "|      03         1.55738322        -0.00000716   |\n",
      "|      04         1.55740772        -0.00000000   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = -5\n",
    "b = 5\n",
    "f = lambda x: np.arctan(x) - 1\n",
    "df = lambda x: 1 / (1 + x**2)\n",
    "x = 1\n",
    "pause = 0\n",
    "xs, ys = newton_animation(f, df, a, b, x, N, \"\", pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceee0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|       n          x_n                f(x_n)      |\n",
      "|=================================================|\n",
      "|      00        10.00000000        -0.69741491   |\n",
      "|      01        16.97414907        -0.16830846   |\n",
      "|      02        19.83104190        -0.01275152   |\n",
      "|      03        20.08391777        -0.00008062   |\n",
      "|      04        20.08553686        -0.00000000   |\n",
      "|_________________________________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "f = lambda x: np.log(x) - 3\n",
    "df = lambda x: 1 / x\n",
    "x = 10\n",
    "xs, ys = newton_animation(f, df, a, b, x, N, \"\", pause)\n",
    "print_solution(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca6b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "49060cedf8366e4ce4bf4b9d121c044cf7249a0afe21432e14f32b1ca5a4731f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
